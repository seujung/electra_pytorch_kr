{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from transformers.modeling_bert import BertConfig, BertModel\n",
    "\n",
    "from salt.data.dataset.bert_dataset import BERTDataSet\n",
    "from salt.data.tokenizer import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "# !wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertmodel = BertModel(BertConfig.from_dict(bert_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.modeling_rezero import ElectraForPretrain\n",
    "from salt.data.tokenizer import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2020 17:00:33 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 1,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 17:00:33 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 17:00:34 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 1,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 17:00:34 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = ElectraForPretrain('./model_config/electra_small_config.json')\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_55000_loss10.827.pth'\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_122000_loss7.173.pth'\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_159000_loss10.434.pth'\n",
    "binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_201000_loss10.286.pth'\n",
    "checkpoint = torch.load(binary_path, map_location={'cuda:0': 'cpu'})\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "state_dict = {k.replace('module.', ''): v for k,v in state_dict.items()}\n",
    "# pretrain_model.load_state_dict(state_dict)\n",
    "bertmodel = pretrain_model.dis_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '/home/dmig/work/test_container/tokenizer/tokenizer_22000.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencepieceTokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('./ratings_train.txt?dl=1', sep='\\t')\n",
    "testset = pd.read_csv('./ratings_test.txt?dl=1', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = trainset.dropna(axis=0)\n",
    "testset = testset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = dict()\n",
    "traindata['text'] =list()\n",
    "traindata['label'] = trainset['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = dict()\n",
    "testdata['text'] =list()\n",
    "testdata['label'] = testset['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from salt.preprocessor.normalizer import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainset['document'].tolist():\n",
    "    traindata['text'].append([normalize(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testset['document'].tolist():\n",
    "    testdata['text'].append([normalize(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[generating BERT dataset]: 100%|██████████| 149995/149995 [00:09<00:00, 15729.02it/s]\n",
      "[generating BERT dataset]: 100%|██████████| 49997/49997 [00:03<00:00, 16093.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = BERTDataSet(data = traindata, text_idx = 'text', label_idx = 'label', tokenizer = tokenizer, max_seq_len=max_len, pad=True, pair=False)\n",
    "test_data = BERTDataSet(data = testdata, text_idx = 'text', label_idx = 'label', tokenizer = tokenizer, max_seq_len=max_len, pad=True, pair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel, hidden_size=256, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gen_attention_mask(token_ids, valid_length):\n",
    "    attention_mask = torch.zeros_like(token_ids)\n",
    "    for i, v in enumerate(valid_length):\n",
    "        attention_mask[i][:v] = 1\n",
    "    return attention_mask.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d169bd0152664552ac59cb799fab966e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.7257020473480225 train acc 0.46875\n",
      "epoch 1 batch id 201 loss 0.7310513257980347 train acc 0.5002332089552238\n",
      "epoch 1 batch id 401 loss 0.6948056221008301 train acc 0.49551901496259354\n",
      "epoch 1 batch id 601 loss 0.7033348679542542 train acc 0.4964642262895175\n",
      "epoch 1 batch id 801 loss 0.7151772379875183 train acc 0.4968984082397004\n",
      "epoch 1 batch id 1001 loss 0.6797340512275696 train acc 0.49740884115884115\n",
      "epoch 1 batch id 1201 loss 0.658115804195404 train acc 0.4977362614487927\n",
      "epoch 1 batch id 1401 loss 0.690140426158905 train acc 0.49852783725910066\n",
      "epoch 1 batch id 1601 loss 0.7027692198753357 train acc 0.4981066520924422\n",
      "epoch 1 batch id 1801 loss 0.6577820777893066 train acc 0.5007721404775125\n",
      "epoch 1 batch id 2001 loss 0.5384700298309326 train acc 0.5226215017491255\n",
      "epoch 1 batch id 2201 loss 0.3780318796634674 train acc 0.546690424806906\n",
      "\n",
      "epoch 1 train acc 0.5630171541392174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd63ab977fd34ecc88127e89e8bc1415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 test acc 0.8125630164273067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866a41d7bc5f4a718bd4a466919e6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.7100959420204163 train acc 0.65625\n",
      "epoch 2 batch id 201 loss 0.3885534703731537 train acc 0.8194962686567164\n",
      "epoch 2 batch id 401 loss 0.3700013756752014 train acc 0.8182278678304239\n",
      "epoch 2 batch id 601 loss 0.4059150815010071 train acc 0.8209494592346089\n",
      "epoch 2 batch id 801 loss 0.438575804233551 train acc 0.8234433520599251\n",
      "epoch 2 batch id 1001 loss 0.28438618779182434 train acc 0.8247065434565435\n",
      "epoch 2 batch id 1201 loss 0.3687033951282501 train acc 0.8257311615320566\n",
      "epoch 2 batch id 1401 loss 0.43567243218421936 train acc 0.8264297822983583\n",
      "epoch 2 batch id 1601 loss 0.4300857186317444 train acc 0.8272076046221112\n",
      "epoch 2 batch id 1801 loss 0.46287357807159424 train acc 0.8285761382565242\n",
      "epoch 2 batch id 2001 loss 0.390890508890152 train acc 0.8304285357321339\n",
      "epoch 2 batch id 2201 loss 0.2778278589248657 train acc 0.8326257950931395\n",
      "\n",
      "epoch 2 train acc 0.8345213719838876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d7a6f295b44acdb41fc8124f439e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 test acc 0.8388762172929373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc74f91a0ff476ab1da90a19ed99d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.6023924350738525 train acc 0.734375\n",
      "epoch 3 batch id 201 loss 0.33359652757644653 train acc 0.8558768656716418\n",
      "epoch 3 batch id 401 loss 0.2919536828994751 train acc 0.8559850374064838\n",
      "epoch 3 batch id 601 loss 0.3527991771697998 train acc 0.8555272462562395\n",
      "epoch 3 batch id 801 loss 0.3955630362033844 train acc 0.8561953807740325\n",
      "epoch 3 batch id 1001 loss 0.2924390435218811 train acc 0.8550668081918081\n",
      "epoch 3 batch id 1201 loss 0.34994643926620483 train acc 0.8540929433805162\n",
      "epoch 3 batch id 1401 loss 0.4000101387500763 train acc 0.8533302105638829\n",
      "epoch 3 batch id 1601 loss 0.3715963065624237 train acc 0.8526116489693941\n",
      "epoch 3 batch id 1801 loss 0.4654548168182373 train acc 0.8528334952803998\n",
      "epoch 3 batch id 2001 loss 0.36421361565589905 train acc 0.8533858070964517\n",
      "epoch 3 batch id 2201 loss 0.27078044414520264 train acc 0.8546470354384371\n",
      "\n",
      "epoch 3 train acc 0.8556591172910548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e8f539b95f40bba3695fc7f3ff9b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 test acc 0.8412954333071021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5684ab0f36bf4333b45844a5553ee6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.5827285647392273 train acc 0.765625\n",
      "epoch 4 batch id 201 loss 0.3150353729724884 train acc 0.8644278606965174\n",
      "epoch 4 batch id 401 loss 0.27514544129371643 train acc 0.8651807980049875\n",
      "epoch 4 batch id 601 loss 0.3201715350151062 train acc 0.8650686356073212\n",
      "epoch 4 batch id 801 loss 0.373264878988266 train acc 0.8654611423220974\n",
      "epoch 4 batch id 1001 loss 0.26721230149269104 train acc 0.8644948801198801\n",
      "epoch 4 batch id 1201 loss 0.3310320973396301 train acc 0.8639935470441299\n",
      "epoch 4 batch id 1401 loss 0.3817404806613922 train acc 0.8631334760885082\n",
      "epoch 4 batch id 1601 loss 0.31175100803375244 train acc 0.8627908338538414\n",
      "epoch 4 batch id 1801 loss 0.4340623617172241 train acc 0.8628973486951693\n",
      "epoch 4 batch id 2001 loss 0.40219196677207947 train acc 0.8632949150424788\n",
      "epoch 4 batch id 2201 loss 0.2521302402019501 train acc 0.8642236483416629\n",
      "\n",
      "epoch 4 train acc 0.8653148315342488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead05074fd384134a0baae2b2e48c61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 test acc 0.8406160854810151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e406a91bc2a44a6ea30fbfb6b15acc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.5252546072006226 train acc 0.78125\n",
      "epoch 5 batch id 201 loss 0.2842329740524292 train acc 0.8732120646766169\n",
      "epoch 5 batch id 401 loss 0.2991602122783661 train acc 0.8747272443890274\n",
      "epoch 5 batch id 601 loss 0.34600937366485596 train acc 0.8742200499168054\n",
      "epoch 5 batch id 801 loss 0.31162580847740173 train acc 0.8743367665418227\n",
      "epoch 5 batch id 1001 loss 0.2544440031051636 train acc 0.8736263736263736\n",
      "epoch 5 batch id 1201 loss 0.33059778809547424 train acc 0.8731916111573689\n",
      "epoch 5 batch id 1401 loss 0.3210889995098114 train acc 0.8720556745182013\n",
      "epoch 5 batch id 1601 loss 0.2686362564563751 train acc 0.8713499375390381\n",
      "epoch 5 batch id 1801 loss 0.416944682598114 train acc 0.8715470571904498\n",
      "epoch 5 batch id 2001 loss 0.3444525897502899 train acc 0.8717750499750125\n",
      "epoch 5 batch id 2201 loss 0.21955034136772156 train acc 0.8727070081781009\n",
      "\n",
      "epoch 5 train acc 0.8736472760734979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65bbd901cb14f1491d1b3a783f87ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 test acc 0.8405161813889435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b1d16264f04f80a61fb0acc18c7d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.4989190697669983 train acc 0.8125\n",
      "epoch 6 batch id 201 loss 0.2507878541946411 train acc 0.8795864427860697\n",
      "epoch 6 batch id 401 loss 0.25159454345703125 train acc 0.8815461346633416\n",
      "epoch 6 batch id 601 loss 0.29091745615005493 train acc 0.8807456322795341\n",
      "epoch 6 batch id 801 loss 0.29379281401634216 train acc 0.8816518414481898\n",
      "epoch 6 batch id 1001 loss 0.20558911561965942 train acc 0.8808847402597403\n",
      "epoch 6 batch id 1201 loss 0.3273458480834961 train acc 0.8800869067443797\n",
      "epoch 6 batch id 1401 loss 0.29215070605278015 train acc 0.8793941827266238\n",
      "epoch 6 batch id 1601 loss 0.2512838542461395 train acc 0.878864772017489\n",
      "epoch 6 batch id 1801 loss 0.3709067106246948 train acc 0.8791036229872293\n",
      "epoch 6 batch id 2001 loss 0.33287957310676575 train acc 0.8795680284857571\n",
      "epoch 6 batch id 2201 loss 0.1947292685508728 train acc 0.8802887891867333\n",
      "\n",
      "epoch 6 train acc 0.8810430763354233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03392d8a391436c879d0c3241dc0692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 test acc 0.8384181954554396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d254e9bfa9a41dbb33dfa75b083ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.5049951672554016 train acc 0.8125\n",
      "epoch 7 batch id 201 loss 0.26472243666648865 train acc 0.8889148009950248\n",
      "epoch 7 batch id 401 loss 0.2126031517982483 train acc 0.8903132793017456\n",
      "epoch 7 batch id 601 loss 0.27130070328712463 train acc 0.8891170965058236\n",
      "epoch 7 batch id 801 loss 0.2773917317390442 train acc 0.8901178214731585\n",
      "epoch 7 batch id 1001 loss 0.22347691655158997 train acc 0.8892357642357642\n",
      "epoch 7 batch id 1201 loss 0.3346298933029175 train acc 0.8877758118234804\n",
      "epoch 7 batch id 1401 loss 0.2848488688468933 train acc 0.8871564953604568\n",
      "epoch 7 batch id 1601 loss 0.22445005178451538 train acc 0.8867992660836976\n",
      "epoch 7 batch id 1801 loss 0.3938150405883789 train acc 0.8870939755691283\n",
      "epoch 7 batch id 2001 loss 0.3146064877510071 train acc 0.8872829210394803\n",
      "epoch 7 batch id 2201 loss 0.20497435331344604 train acc 0.8880125511131304\n",
      "\n",
      "epoch 7 train acc 0.8887456655786173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f52a1b2815549aa89a294d569f48ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 test acc 0.8376589243556954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2990b6ca204fbd9ba189c7488241bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.5074476599693298 train acc 0.8125\n",
      "epoch 8 batch id 201 loss 0.2426416277885437 train acc 0.8929570895522388\n",
      "epoch 8 batch id 401 loss 0.16904719173908234 train acc 0.8954566708229427\n",
      "epoch 8 batch id 601 loss 0.2585350275039673 train acc 0.8938487936772047\n",
      "epoch 8 batch id 801 loss 0.21219070255756378 train acc 0.8941362359550562\n",
      "epoch 8 batch id 1001 loss 0.16813042759895325 train acc 0.893419080919081\n",
      "epoch 8 batch id 1201 loss 0.32563599944114685 train acc 0.8925895087427144\n",
      "epoch 8 batch id 1401 loss 0.2853933572769165 train acc 0.8923202177016417\n",
      "epoch 8 batch id 1601 loss 0.16870994865894318 train acc 0.8915911930043723\n",
      "epoch 8 batch id 1801 loss 0.3742367923259735 train acc 0.8917268184342032\n",
      "epoch 8 batch id 2001 loss 0.3720835745334625 train acc 0.8917182033983009\n",
      "epoch 8 batch id 2201 loss 0.21287745237350464 train acc 0.8924068605179464\n",
      "\n",
      "epoch 8 train acc 0.8931351198507818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32014c1b4b9f494cb26b3a7f8a500fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 test acc 0.8366798642533936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dba3cbfe3d24eedb85ece3d5aefaa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.516160249710083 train acc 0.8125\n",
      "epoch 9 batch id 201 loss 0.22874940931797028 train acc 0.9005752487562189\n",
      "epoch 9 batch id 401 loss 0.16607902944087982 train acc 0.90169108478803\n",
      "epoch 9 batch id 601 loss 0.21741262078285217 train acc 0.9004783693843594\n",
      "epoch 9 batch id 801 loss 0.1916283220052719 train acc 0.9011001872659176\n",
      "epoch 9 batch id 1001 loss 0.14797671139240265 train acc 0.8995535714285714\n",
      "epoch 9 batch id 1201 loss 0.34800055623054504 train acc 0.8981317651956703\n",
      "epoch 9 batch id 1401 loss 0.2961972653865814 train acc 0.8974616345467523\n",
      "epoch 9 batch id 1601 loss 0.18215464055538177 train acc 0.897007729544035\n",
      "epoch 9 batch id 1801 loss 0.33541637659072876 train acc 0.897296640755136\n",
      "epoch 9 batch id 2001 loss 0.3324943482875824 train acc 0.8974184782608695\n",
      "epoch 9 batch id 2201 loss 0.19261199235916138 train acc 0.8980577010449795\n",
      "\n",
      "epoch 9 train acc 0.8987878502262083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bdbb503b354069b7f7161016c01896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 test acc 0.8358806315168207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f37b70822b14d51acff34929d66f26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.4459599256515503 train acc 0.8125\n",
      "epoch 10 batch id 201 loss 0.18447867035865784 train acc 0.9044620646766169\n",
      "epoch 10 batch id 401 loss 0.1373143196105957 train acc 0.9058213840399002\n",
      "epoch 10 batch id 601 loss 0.22898145020008087 train acc 0.9043781198003328\n",
      "epoch 10 batch id 801 loss 0.18592312932014465 train acc 0.9045138888888888\n",
      "epoch 10 batch id 1001 loss 0.17885860800743103 train acc 0.9032842157842158\n",
      "epoch 10 batch id 1201 loss 0.32378682494163513 train acc 0.9021518526228143\n",
      "epoch 10 batch id 1401 loss 0.3038676381111145 train acc 0.9014431655960029\n",
      "epoch 10 batch id 1601 loss 0.17385226488113403 train acc 0.9010188944409744\n",
      "epoch 10 batch id 1801 loss 0.3726145625114441 train acc 0.901079261521377\n",
      "epoch 10 batch id 2001 loss 0.2546845078468323 train acc 0.9011041354322838\n",
      "epoch 10 batch id 2201 loss 0.22223028540611267 train acc 0.9015291344843253\n",
      "\n",
      "epoch 10 train acc 0.9021374154198746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2116f4af7604463b3e5a162024a2669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 test acc 0.8359205931536494\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
