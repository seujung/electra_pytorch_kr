{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/dmig/py_libs/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from transformers.modeling_bert import BertConfig, BertModel\n",
    "\n",
    "from salt.data.dataset.bert_dataset import BERTDataSet\n",
    "from salt.data.tokenizer import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "# !wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertmodel = BertModel(BertConfig.from_dict(bert_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2020 11:57:47 - INFO - model.file_utils -   PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "from model.modeling_electra import ElectraForPretrain\n",
    "from salt.data.tokenizer import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/30/2020 11:58:17 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 1,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 11:58:17 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 11:58:17 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 64,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 256,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 1,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "03/30/2020 11:58:17 - INFO - model.configuration_utils -   Model config ElectraConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embedding_size\": 256,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"generator_ratio\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"padding_idx\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = ElectraForPretrain('./model_config/electra_small_config.json')\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_55000_loss10.827.pth'\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_122000_loss7.173.pth'\n",
    "# binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_159000_loss10.434.pth'\n",
    "binary_path = '/home/dmig/work/test_container/binary/electra/token_22000/small/models/electra_step_201000_loss10.286.pth'\n",
    "checkpoint = torch.load(binary_path, map_location={'cuda:0': 'cpu'})\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "state_dict = {k.replace('module.', ''): v for k,v in state_dict.items()}\n",
    "pretrain_model.load_state_dict(state_dict)\n",
    "bertmodel = pretrain_model.dis_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '/home/dmig/work/test_container/tokenizer/tokenizer_22000.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencepieceTokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('./ratings_train.txt?dl=1', sep='\\t')\n",
    "testset = pd.read_csv('./ratings_test.txt?dl=1', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = trainset.dropna(axis=0)\n",
    "testset = testset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = dict()\n",
    "traindata['text'] =list()\n",
    "traindata['label'] = trainset['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = dict()\n",
    "testdata['text'] =list()\n",
    "testdata['label'] = testset['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from salt.preprocessor.normalizer import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainset['document'].tolist():\n",
    "    traindata['text'].append([normalize(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testset['document'].tolist():\n",
    "    testdata['text'].append([normalize(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[generating BERT dataset]: 100%|██████████| 149995/149995 [00:09<00:00, 15908.48it/s]\n",
      "[generating BERT dataset]: 100%|██████████| 49997/49997 [00:03<00:00, 15992.54it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = BERTDataSet(data = traindata, text_idx = 'text', label_idx = 'label', tokenizer = tokenizer, max_seq_len=max_len, pad=True, pair=False)\n",
    "test_data = BERTDataSet(data = testdata, text_idx = 'text', label_idx = 'label', tokenizer = tokenizer, max_seq_len=max_len, pad=True, pair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel, hidden_size=256, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gen_attention_mask(token_ids, valid_length):\n",
    "    attention_mask = torch.zeros_like(token_ids)\n",
    "    for i, v in enumerate(valid_length):\n",
    "        attention_mask[i][:v] = 1\n",
    "    return attention_mask.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f695ceb25fce47908378c1cd9051ee0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.30781763792037964 train acc 0.890625\n",
      "epoch 1 batch id 201 loss 0.14335723221302032 train acc 0.9384328358208955\n",
      "epoch 1 batch id 401 loss 0.13531407713890076 train acc 0.9378117206982544\n",
      "epoch 1 batch id 601 loss 0.2521513104438782 train acc 0.9382539517470881\n",
      "epoch 1 batch id 801 loss 0.20836767554283142 train acc 0.9377730961298377\n",
      "epoch 1 batch id 1001 loss 0.21005457639694214 train acc 0.9370785464535465\n",
      "epoch 1 batch id 1201 loss 0.12816943228244781 train acc 0.9368495004163198\n",
      "epoch 1 batch id 1401 loss 0.23530995845794678 train acc 0.9363735724482513\n",
      "epoch 1 batch id 1601 loss 0.22132864594459534 train acc 0.9360360712054966\n",
      "epoch 1 batch id 1801 loss 0.14328327775001526 train acc 0.9359296918378679\n",
      "epoch 1 batch id 2001 loss 0.247671976685524 train acc 0.9359070464767616\n",
      "epoch 1 batch id 2201 loss 0.09174485504627228 train acc 0.9358388232621536\n",
      "\n",
      "epoch 1 train acc 0.9359102470930232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a0bc8999ba449dad7f70489ec408f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b1fd5568cd41af9a091639fa1ddc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3279961347579956 train acc 0.875\n",
      "epoch 2 batch id 201 loss 0.19918538630008698 train acc 0.9359452736318408\n",
      "epoch 2 batch id 401 loss 0.09562499821186066 train acc 0.9363310473815462\n",
      "epoch 2 batch id 601 loss 0.2714020311832428 train acc 0.9372920133111481\n",
      "epoch 2 batch id 801 loss 0.19827067852020264 train acc 0.9379876716604245\n",
      "epoch 2 batch id 1001 loss 0.26120755076408386 train acc 0.9372502497502497\n",
      "epoch 2 batch id 1201 loss 0.15501363575458527 train acc 0.9366673605328892\n",
      "epoch 2 batch id 1401 loss 0.23144735395908356 train acc 0.9362397394718058\n",
      "epoch 2 batch id 1601 loss 0.24361149966716766 train acc 0.935957995003123\n",
      "epoch 2 batch id 1801 loss 0.15718580782413483 train acc 0.9357127984453082\n",
      "epoch 2 batch id 2001 loss 0.2596357762813568 train acc 0.9356805972013993\n",
      "epoch 2 batch id 2201 loss 0.05511324480175972 train acc 0.9353773852794185\n",
      "\n",
      "epoch 2 train acc 0.9358003363362172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e123b2652614e159341462bfe6101c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137824a8a4f144d7883d62dfe130f72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.4099917709827423 train acc 0.84375\n",
      "epoch 3 batch id 201 loss 0.23668067157268524 train acc 0.9331467661691543\n",
      "epoch 3 batch id 401 loss 0.14883995056152344 train acc 0.9349283042394015\n",
      "epoch 3 batch id 601 loss 0.2642366588115692 train acc 0.9357841098169717\n",
      "epoch 3 batch id 801 loss 0.23070818185806274 train acc 0.9358224094881398\n",
      "epoch 3 batch id 1001 loss 0.23921459913253784 train acc 0.9358922327672328\n",
      "epoch 3 batch id 1201 loss 0.13604795932769775 train acc 0.9351842214820982\n",
      "epoch 3 batch id 1401 loss 0.23888327181339264 train acc 0.9346672019985724\n",
      "epoch 3 batch id 1601 loss 0.258232057094574 train acc 0.9348063710181137\n",
      "epoch 3 batch id 1801 loss 0.11772524565458298 train acc 0.9350274153248196\n",
      "epoch 3 batch id 2001 loss 0.26564034819602966 train acc 0.935297976011994\n",
      "epoch 3 batch id 2201 loss 0.1357443630695343 train acc 0.9352638005452067\n",
      "\n",
      "epoch 3 train acc 0.9354603725990158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dcbf0de1154074aaa32432fbfffa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e956381034b64090a5b843a452770226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.3544045388698578 train acc 0.890625\n",
      "epoch 4 batch id 201 loss 0.19850526750087738 train acc 0.9361784825870647\n",
      "epoch 4 batch id 401 loss 0.1742056906223297 train acc 0.9366427680798005\n",
      "epoch 4 batch id 601 loss 0.22665847837924957 train acc 0.9365900582362728\n",
      "epoch 4 batch id 801 loss 0.283020555973053 train acc 0.9363490948813983\n",
      "epoch 4 batch id 1001 loss 0.21246609091758728 train acc 0.9360327172827173\n",
      "epoch 4 batch id 1201 loss 0.13960054516792297 train acc 0.9358087010824313\n",
      "epoch 4 batch id 1401 loss 0.27803295850753784 train acc 0.9354144361170592\n",
      "epoch 4 batch id 1601 loss 0.19567273557186127 train acc 0.9354212211118051\n",
      "epoch 4 batch id 1801 loss 0.17061394453048706 train acc 0.9354091476957246\n",
      "epoch 4 batch id 2001 loss 0.19127364456653595 train acc 0.9355868940529735\n",
      "epoch 4 batch id 2201 loss 0.08103649318218231 train acc 0.9357252385279419\n",
      "\n",
      "epoch 4 train acc 0.9357670065580602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194097342c664accaa8e58741161bce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ae49328be84b07a3bc6d42e527dfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.29936718940734863 train acc 0.859375\n",
      "epoch 5 batch id 201 loss 0.18927431106567383 train acc 0.9340796019900498\n",
      "epoch 5 batch id 401 loss 0.18593120574951172 train acc 0.9348114089775561\n",
      "epoch 5 batch id 601 loss 0.2827187776565552 train acc 0.9356801164725458\n",
      "epoch 5 batch id 801 loss 0.14695227146148682 train acc 0.9360759987515606\n",
      "epoch 5 batch id 1001 loss 0.22952759265899658 train acc 0.9350961538461539\n",
      "epoch 5 batch id 1201 loss 0.11875797808170319 train acc 0.934533721898418\n",
      "epoch 5 batch id 1401 loss 0.22969718277454376 train acc 0.9345222162740899\n",
      "epoch 5 batch id 1601 loss 0.23069745302200317 train acc 0.9342207995003123\n",
      "epoch 5 batch id 1801 loss 0.10851491987705231 train acc 0.9344201138256524\n",
      "epoch 5 batch id 2001 loss 0.3451370298862457 train acc 0.9347826086956522\n",
      "epoch 5 batch id 2201 loss 0.11281037330627441 train acc 0.9347881644706951\n",
      "\n",
      "epoch 5 train acc 0.934947249037622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6cd6ed0ea648a1bc5b4bbecb4ca0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab79b941ec74fc7b27b3701debd34ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.3720177412033081 train acc 0.84375\n",
      "epoch 6 batch id 201 loss 0.19181612133979797 train acc 0.9371113184079602\n",
      "epoch 6 batch id 401 loss 0.12695062160491943 train acc 0.9366427680798005\n",
      "epoch 6 batch id 601 loss 0.3218015432357788 train acc 0.9371880199667221\n",
      "epoch 6 batch id 801 loss 0.1945500522851944 train acc 0.9371683832709113\n",
      "epoch 6 batch id 1001 loss 0.3145107626914978 train acc 0.9363917332667333\n",
      "epoch 6 batch id 1201 loss 0.11246959865093231 train acc 0.9358737510407993\n",
      "epoch 6 batch id 1401 loss 0.2476348727941513 train acc 0.9358493932905068\n",
      "epoch 6 batch id 1601 loss 0.26063552498817444 train acc 0.9355578544659587\n",
      "epoch 6 batch id 1801 loss 0.11427875608205795 train acc 0.9355132565241533\n",
      "epoch 6 batch id 2001 loss 0.2355523556470871 train acc 0.9357821089455273\n",
      "epoch 6 batch id 2201 loss 0.1739010065793991 train acc 0.9356471490231713\n",
      "\n",
      "epoch 6 train acc 0.935723600335344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aff4fa90db34ba19edeb4e8c9dc7bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6ee708248b43d68bf20df3422197ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.4277228116989136 train acc 0.828125\n",
      "epoch 7 batch id 201 loss 0.2132609635591507 train acc 0.9346237562189055\n",
      "epoch 7 batch id 401 loss 0.18565106391906738 train acc 0.9363310473815462\n",
      "epoch 7 batch id 601 loss 0.1921117752790451 train acc 0.9372660149750416\n",
      "epoch 7 batch id 801 loss 0.2286350429058075 train acc 0.9365246566791511\n",
      "epoch 7 batch id 1001 loss 0.30213844776153564 train acc 0.935939060939061\n",
      "epoch 7 batch id 1201 loss 0.10168814659118652 train acc 0.935717631140716\n",
      "epoch 7 batch id 1401 loss 0.274747759103775 train acc 0.9353475196288366\n",
      "epoch 7 batch id 1601 loss 0.2221226841211319 train acc 0.9352455496564647\n",
      "epoch 7 batch id 1801 loss 0.1927114725112915 train acc 0.935305038867296\n",
      "epoch 7 batch id 2001 loss 0.20698638260364532 train acc 0.9355478510744628\n",
      "epoch 7 batch id 2201 loss 0.11199753731489182 train acc 0.9356542480690595\n",
      "\n",
      "epoch 7 train acc 0.9360271338499088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d894319f64ce4a02a58d34d2db180600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de8fda2e6324d6ab600284c1071c0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.31938332319259644 train acc 0.875\n",
      "epoch 8 batch id 201 loss 0.22547514736652374 train acc 0.9366449004975125\n",
      "epoch 8 batch id 401 loss 0.1103774681687355 train acc 0.9370324189526185\n",
      "epoch 8 batch id 601 loss 0.2328304648399353 train acc 0.937603993344426\n",
      "epoch 8 batch id 801 loss 0.18136587738990784 train acc 0.9374219725343321\n",
      "epoch 8 batch id 1001 loss 0.16291822493076324 train acc 0.9369536713286714\n",
      "epoch 8 batch id 1201 loss 0.13058659434318542 train acc 0.9363681307243963\n",
      "epoch 8 batch id 1401 loss 0.19932805001735687 train acc 0.9359720735189151\n",
      "epoch 8 batch id 1601 loss 0.20019502937793732 train acc 0.9356066520924422\n",
      "epoch 8 batch id 1801 loss 0.17374001443386078 train acc 0.9354959050527485\n",
      "epoch 8 batch id 2001 loss 0.27287405729293823 train acc 0.935508808095952\n",
      "epoch 8 batch id 2201 loss 0.11554523557424545 train acc 0.9353986824170831\n",
      "\n",
      "epoch 8 train acc 0.9357369322466068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30157427eda4712a4a79e3aa2af2970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f7dfc39f514501b74e35d6fd591341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.33788183331489563 train acc 0.859375\n",
      "epoch 9 batch id 201 loss 0.17800867557525635 train acc 0.9361784825870647\n",
      "epoch 9 batch id 401 loss 0.11398687213659286 train acc 0.9370324189526185\n",
      "epoch 9 batch id 601 loss 0.2912108898162842 train acc 0.9371100249584027\n",
      "epoch 9 batch id 801 loss 0.19433587789535522 train acc 0.9374804931335831\n",
      "epoch 9 batch id 1001 loss 0.22225099802017212 train acc 0.9365478271728271\n",
      "epoch 9 batch id 1201 loss 0.15657417476177216 train acc 0.9356786011656952\n",
      "epoch 9 batch id 1401 loss 0.27760007977485657 train acc 0.9352471448965025\n",
      "epoch 9 batch id 1601 loss 0.26320281624794006 train acc 0.9351284353529045\n",
      "epoch 9 batch id 1801 loss 0.19801293313503265 train acc 0.935105496946141\n",
      "epoch 9 batch id 2001 loss 0.26209381222724915 train acc 0.9351808470764618\n",
      "epoch 9 batch id 2201 loss 0.12161140143871307 train acc 0.9349514425261245\n",
      "\n",
      "epoch 9 train acc 0.9351438172176362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e5f4a718434138ba9694f493665171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 test acc 0.8752997122762148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0333657f7a2a4d1f8e2b24a33694dc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.3170332908630371 train acc 0.875\n",
      "epoch 10 batch id 201 loss 0.14119859039783478 train acc 0.9334577114427861\n",
      "epoch 10 batch id 401 loss 0.17781388759613037 train acc 0.9358245012468828\n",
      "epoch 10 batch id 601 loss 0.27473291754722595 train acc 0.9360700915141431\n",
      "epoch 10 batch id 801 loss 0.12813779711723328 train acc 0.936583177278402\n",
      "epoch 10 batch id 1001 loss 0.264318585395813 train acc 0.9361263736263736\n",
      "epoch 10 batch id 1201 loss 0.08390761911869049 train acc 0.9355745212323064\n",
      "epoch 10 batch id 1401 loss 0.20121996104717255 train acc 0.9352582976445396\n",
      "epoch 10 batch id 1601 loss 0.28321683406829834 train acc 0.9351089163023111\n",
      "epoch 10 batch id 1801 loss 0.2013881653547287 train acc 0.9352009300388673\n",
      "epoch 10 batch id 2001 loss 0.2241167277097702 train acc 0.935454147926037\n",
      "epoch 10 batch id 2201 loss 0.08333182334899902 train acc 0.9355974557019536\n",
      "\n",
      "epoch 10 train acc 0.9356104341118342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bc0eabd8a5415bb8fce04a4dcc351d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10 test acc 0.8752997122762148\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
